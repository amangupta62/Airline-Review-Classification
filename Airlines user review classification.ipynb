{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "6c53202d-5c34-4859-e7e9-8ef5c7068287",
    "_uuid": "717bb968c36b9325c7d4cae5724a3672e49ff243"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ht2dn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ht2dn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ht2dn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ht2dn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ht2dn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ht2dn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "89c8c923-c0bf-7b35-9ab8-e63f00b74e5a",
    "_uuid": "d2bc3bbd2ea3961c49e6673145a0a7226c160e58"
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('input/Sentiment.csv')\n",
    "data = pd.read_csv('input/Tweets.csv')\n",
    "# Keeping only the neccessary columns\n",
    "#data = data[['text','sentiment']]\n",
    "data = data[['text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f6a102c71c8e281450f7e73a5678cc9d0bb99e99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076",
    "_uuid": "d0f8b4542106a279f7398db7285ae5e370b2e813"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus youve added commercials to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica its really aggressive to blast o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica and its a really big bad thing a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>virginamerica seriously would pay 30 a flight ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "1  virginamerica plus youve added commercials to ...          positive\n",
       "3  virginamerica its really aggressive to blast o...          negative\n",
       "4  virginamerica and its a really big bad thing a...          negative\n",
       "5  virginamerica seriously would pay 30 a flight ...          negative\n",
       "6  virginamerica yes nearly every time i fly vx t...          positive"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.airline_sentiment != \"neutral\"]\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "# removing special chars\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "#\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076",
    "_uuid": "d0f8b4542106a279f7398db7285ae5e370b2e813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4726\n",
      "18356\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus youve added commercials to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica its really aggressive to blast o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica and its a really big bad thing a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>virginamerica seriously would pay 30 a flight ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "1  virginamerica plus youve added commercials to ...          positive\n",
       "3  virginamerica its really aggressive to blast o...          negative\n",
       "4  virginamerica and its a really big bad thing a...          negative\n",
       "5  virginamerica seriously would pay 30 a flight ...          negative\n",
       "6  virginamerica yes nearly every time i fly vx t...          positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[ data['airline_sentiment'] == 'positive'].size)\n",
    "print(data[ data['airline_sentiment'] == 'negative'].size)\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt','')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076",
    "_uuid": "d0f8b4542106a279f7398db7285ae5e370b2e813"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,   99,  554,  490, 1244,    1,    2,  170],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   99,\n",
       "          65,  120,    1,  928,   15,   20,   59,   53,   25,  469]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "1ba3cf60-a83c-9c21-05e0-b14303027e93",
    "_uuid": "05cb9ef0ec9e0a4067e3ab7c1bda7b2c1211feda",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 32, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "b35748b8-2353-3db2-e571-5fd22bb93eb0",
    "_uuid": "a380bbfae2d098d407b138fc44622c9913a31c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9232, 32) (9232, 2)\n",
      "(2309, 32) (2309, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['airline_sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "d5e499ac-2eba-6ff7-8d9a-ff65eb04099b",
    "_uuid": "d0b239912cf67294a9f5af6883bb159c44318fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ht2dn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "9232/9232 [==============================] - 20s 2ms/step - loss: 0.4068 - accuracy: 0.8253\n",
      "Epoch 2/15\n",
      "9232/9232 [==============================] - 19s 2ms/step - loss: 0.2159 - accuracy: 0.9149\n",
      "Epoch 3/15\n",
      "9232/9232 [==============================] - 20s 2ms/step - loss: 0.1609 - accuracy: 0.9394\n",
      "Epoch 4/15\n",
      "9232/9232 [==============================] - 23s 3ms/step - loss: 0.1344 - accuracy: 0.9488\n",
      "Epoch 5/15\n",
      "9232/9232 [==============================] - 21s 2ms/step - loss: 0.1240 - accuracy: 0.9524\n",
      "Epoch 6/15\n",
      "9232/9232 [==============================] - 22s 2ms/step - loss: 0.1115 - accuracy: 0.9569\n",
      "Epoch 7/15\n",
      "9232/9232 [==============================] - 24s 3ms/step - loss: 0.0996 - accuracy: 0.9615\n",
      "Epoch 8/15\n",
      "9232/9232 [==============================] - 22s 2ms/step - loss: 0.0884 - accuracy: 0.9660\n",
      "Epoch 9/15\n",
      "9232/9232 [==============================] - 23s 2ms/step - loss: 0.0816 - accuracy: 0.9700\n",
      "Epoch 10/15\n",
      "9232/9232 [==============================] - 21s 2ms/step - loss: 0.0660 - accuracy: 0.9750\n",
      "Epoch 11/15\n",
      "9232/9232 [==============================] - 20s 2ms/step - loss: 0.0596 - accuracy: 0.9778\n",
      "Epoch 12/15\n",
      "9232/9232 [==============================] - 19s 2ms/step - loss: 0.0517 - accuracy: 0.9809\n",
      "Epoch 13/15\n",
      "9232/9232 [==============================] - 19s 2ms/step - loss: 0.0522 - accuracy: 0.9800\n",
      "Epoch 14/15\n",
      "9232/9232 [==============================] - 19s 2ms/step - loss: 0.0498 - accuracy: 0.9821\n",
      "Epoch 15/15\n",
      "9232/9232 [==============================] - 19s 2ms/step - loss: 0.0412 - accuracy: 0.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x209464027c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "4701961e44bd243e505fc2c1b53b323311ad2b80"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict_classes(X_test,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "13d9f618b3b74f881d68aed864a26249d26e63de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[1783   79]\n",
      " [ 105  342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1862\n",
      "           1       0.81      0.77      0.79       447\n",
      "\n",
      "    accuracy                           0.92      2309\n",
      "   macro avg       0.88      0.86      0.87      2309\n",
      "weighted avg       0.92      0.92      0.92      2309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
    "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
    "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
    "print(classification_report(df_test.true, df_test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "384ed509b57715fbc7cce5ad37802a8785603b52"
   },
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "data_majority = data[data['airline_sentiment'] == 'negative']\n",
    "data_minority = data[data['airline_sentiment'] == 'positive']\n",
    "\n",
    "bias = data_minority.shape[0]/data_majority.shape[0]\n",
    "# lets split train/test data first then \n",
    "train = pd.concat([data_majority.sample(frac=0.8,random_state=200),\n",
    "         data_minority.sample(frac=0.8,random_state=200)])\n",
    "test = pd.concat([data_majority.drop(data_majority.sample(frac=0.8,random_state=200).index),\n",
    "        data_minority.drop(data_minority.sample(frac=0.8,random_state=200).index)])\n",
    "\n",
    "train = shuffle(train)\n",
    "test = shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "ce10e582bd894ec271f2587ceb618a9cf8ab03c5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive data in training: 1890\n",
      "negative data in training: 7342\n",
      "positive data in test: 473\n",
      "negative data in test: 1836\n"
     ]
    }
   ],
   "source": [
    "print('positive data in training:',(train.airline_sentiment == 'positive').sum())\n",
    "print('negative data in training:',(train.airline_sentiment == 'negative').sum())\n",
    "print('positive data in test:',(test.airline_sentiment == 'positive').sum())\n",
    "print('negative data in test:',(test.airline_sentiment == 'negative').sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "384ed509b57715fbc7cce5ad37802a8785603b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class before upsample: (7342, 2)\n",
      "minority class before upsample: (1890, 2)\n",
      "After upsampling\n",
      "positive    7342\n",
      "negative    7342\n",
      "Name: airline_sentiment, dtype: int64\n",
      "x_train shape: (14684, 29)\n",
      "x_test shape (2309, 29)\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes in training data for upsampling \n",
    "data_majority = train[train['airline_sentiment'] == 'negative']\n",
    "data_minority = train[train['airline_sentiment'] == 'positive']\n",
    "\n",
    "print(\"majority class before upsample:\",data_majority.shape)\n",
    "print(\"minority class before upsample:\",data_minority.shape)\n",
    "\n",
    "# Upsample minority class\n",
    "data_minority_upsampled = resample(data_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples= data_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"After upsampling\\n\",data_upsampled.airline_sentiment.value_counts(),sep = \"\")\n",
    "\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values) # training with whole data\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_upsampled['text'].values)\n",
    "X_train = pad_sequences(X_train,maxlen=29)\n",
    "Y_train = pd.get_dummies(data_upsampled['airline_sentiment']).values\n",
    "print('x_train shape:',X_train.shape)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
    "X_test = pad_sequences(X_test,maxlen=29)\n",
    "Y_test = pd.get_dummies(test['airline_sentiment']).values\n",
    "print(\"x_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "1ba3cf60-a83c-9c21-05e0-b14303027e93",
    "_uuid": "05cb9ef0ec9e0a4067e3ab7c1bda7b2c1211feda",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 29, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 192)               246528    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 502,914\n",
      "Trainable params: 502,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "embed_dim = 128\n",
    "lstm_out = 192\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "d5e499ac-2eba-6ff7-8d9a-ff65eb04099b",
    "_uuid": "d0b239912cf67294a9f5af6883bb159c44318fc7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "14684/14684 [==============================] - 32s 2ms/step - loss: 1.0238 - accuracy: 0.6560\n",
      "Epoch 2/15\n",
      "14684/14684 [==============================] - 35s 2ms/step - loss: 0.4634 - accuracy: 0.8750\n",
      "Epoch 3/15\n",
      "14684/14684 [==============================] - 31s 2ms/step - loss: 0.3499 - accuracy: 0.9105\n",
      "Epoch 4/15\n",
      "14684/14684 [==============================] - 28s 2ms/step - loss: 0.2788 - accuracy: 0.9309\n",
      "Epoch 5/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.2415 - accuracy: 0.9401\n",
      "Epoch 6/15\n",
      "14684/14684 [==============================] - 28s 2ms/step - loss: 0.2094 - accuracy: 0.9504\n",
      "Epoch 7/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.1891 - accuracy: 0.9556\n",
      "Epoch 8/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.1733 - accuracy: 0.9569\n",
      "Epoch 9/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.1676 - accuracy: 0.9598\n",
      "Epoch 10/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.1450 - accuracy: 0.9641\n",
      "Epoch 11/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.1358 - accuracy: 0.9699\n",
      "Epoch 12/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.1254 - accuracy: 0.9706\n",
      "Epoch 13/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.1165 - accuracy: 0.9726\n",
      "Epoch 14/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.1166 - accuracy: 0.9728\n",
      "Epoch 15/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.1172 - accuracy: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x209496d1d88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# also adding weights\n",
    "class_weights = {0: 1 ,\n",
    "                1: 1.6/bias }\n",
    "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "2803c5699e0aec22463aadccd1255e63155c1b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[1659  177]\n",
      " [  78  395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1836\n",
      "           1       0.69      0.84      0.76       473\n",
      "\n",
      "    accuracy                           0.89      2309\n",
      "   macro avg       0.82      0.87      0.84      2309\n",
      "weighted avg       0.90      0.89      0.89      2309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_classes(X_test,batch_size = batch_size)\n",
    "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
    "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
    "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
    "print(classification_report(df_test.true, df_test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "085294a5409b58c2188019177041ceb1756f1826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "14684/14684 [==============================] - 28s 2ms/step - loss: 0.1042 - accuracy: 0.9756\n",
      "Epoch 2/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.1016 - accuracy: 0.9769\n",
      "Epoch 3/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.0921 - accuracy: 0.9790\n",
      "Epoch 4/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.0884 - accuracy: 0.9803\n",
      "Epoch 5/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.0799 - accuracy: 0.9822\n",
      "Epoch 6/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.0712 - accuracy: 0.9827\n",
      "Epoch 7/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.0721 - accuracy: 0.9852\n",
      "Epoch 8/15\n",
      "14684/14684 [==============================] - 26s 2ms/step - loss: 0.0704 - accuracy: 0.9847\n",
      "Epoch 9/15\n",
      "14684/14684 [==============================] - 31s 2ms/step - loss: 0.0721 - accuracy: 0.9831\n",
      "Epoch 10/15\n",
      "14684/14684 [==============================] - 30s 2ms/step - loss: 0.0701 - accuracy: 0.9830\n",
      "Epoch 11/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.0633 - accuracy: 0.9862\n",
      "Epoch 12/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.0588 - accuracy: 0.9861\n",
      "Epoch 13/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.0500 - accuracy: 0.9876\n",
      "Epoch 14/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.0677 - accuracy: 0.9851\n",
      "Epoch 15/15\n",
      "14684/14684 [==============================] - 27s 2ms/step - loss: 0.0593 - accuracy: 0.9872\n",
      "confusion matrix [[1688  148]\n",
      " [  87  386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      1836\n",
      "           1       0.72      0.82      0.77       473\n",
      "\n",
      "    accuracy                           0.90      2309\n",
      "   macro avg       0.84      0.87      0.85      2309\n",
      "weighted avg       0.90      0.90      0.90      2309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running model to few more epochs\n",
    "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1,\n",
    "          class_weight=class_weights)\n",
    "Y_pred = model.predict_classes(X_test,batch_size = batch_size)\n",
    "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
    "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
    "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
    "print(classification_report(df_test.true, df_test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "\n",
    "# Consumer keys and access tokens, used for OAuth\n",
    "consumer_key = '****************'\n",
    "consumer_secret = '*********************'\n",
    "access_token = '***********************'\n",
    "access_token_secret = '*************************'\n",
    "\n",
    "# OAuth process, using the keys and tokens\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Creation of the actual interface, using authentication\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "all_twt = []\n",
    "hashtag_phrase = '@IndiGo6E'\n",
    "#get the name of the spreadsheet we will write to\n",
    "fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
    "\n",
    "#open the spreadsheet we will write to\n",
    "with open('%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "\n",
    "    w = csv.writer(file)\n",
    "\n",
    "    #write header row to spreadsheet\n",
    "    w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
    "\n",
    "    #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
    "    for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
    "                                   lang=\"en\", tweet_mode='extended').items():\n",
    "        all_twt.append(tweet.full_text)\n",
    "        w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
    "\n",
    "# all_twt = []\n",
    "# for tweet in tweepy.Cursor(api.search, q='@IndiGo6E'+' -filter:retweets',lang=\"en\", tweet_mode='extended').items():\n",
    "#     #print(tweet.full_text)\n",
    "#     all_twt.append(tweet.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "print(len(all_twt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(all_twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "print(len(twt))\n",
    "cls = model.predict_classes(twt,batch_size = batch_size)\n",
    "# for tt in twt:\n",
    "#     print(tt)\n",
    "#     sentiment = model.predict(tt,batch_size=1,verbose = 2)[0]\n",
    "#     if(np.argmax(sentiment) == 0):\n",
    "#         print(\"negative\")\n",
    "#         neg += 1\n",
    "#     elif (np.argmax(sentiment) == 1):\n",
    "#         print(\"positive\")\n",
    "#         pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of positive reviews are  38\n",
      "total no of negative reviews are  155\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for i in cls:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "    else:\n",
    "        pos += 1\n",
    "\n",
    "print('total no of positive reviews are ', pos)\n",
    "\n",
    "print('total no of negative reviews are ', neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_cell_guid": "24c64f46-edd1-8d0b-7c7c-ef50fd26b2fd",
    "_uuid": "d9aac68e2013b3beffb6a764cc5b85be83073e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@submariner_RSG @IndiGo6E I think indico is one of the uncultured air company. They are doing miss behaving with his passenger on routine basis. All indian media has reported these incidents. We should avoid .....to save our self respect and money also.\n"
     ]
    }
   ],
   "source": [
    "twt = all_twt[0]\n",
    "print(twt)\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "# twt = tokenizer.texts_to_sequences(twt)\n",
    "# #padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "# twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "# print(twt)\n",
    "# sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "# if(np.argmax(sentiment) == 0):\n",
    "#     print(\"negative\")\n",
    "# elif (np.argmax(sentiment) == 1):\n",
    "#     print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "c611b55c-92e4-4a33-8e82-1812bef6193d",
    "_uuid": "8b10995b0832ec98ba0c75832186fcb09b1a2d5f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
